# Credit Card Transaction Fraud Detection 
The project began with a data quality report on the dataset containing company credit card transaction data from a U.S. government organization in 2010. The data holds 18 fields with 96,753 records. The following credit card transaction fields are card number, date, transaction type, and amount. The following fields concerning the merchant are merchant number, merchant description, merchant state, and merchant zip code. A fraud field is present to label whether the transaction is legitimate. This field contains binary values of 0 or 1, where 1 is a fraudulent application record and 0 is normal. Most applicant records have a fraud of 0 with 95,694 occurrences. Applicants with fraud of 1 have 1,059 occurrences. 

Before further investigation, the data had to be properly cleaned. Eight extraneous empty fields were dropped and one outlier was removed due to its extremely high value. Transactions that were not purchases, ‘P’, were filtered out. The following fields: Merchnum, Merch state, and Merch zip, contain missing values. Missing values were filled with carefully designed data imputation techniques.

With the data cleaned, as many as possible candidate variables were created. These variables try to capture signals of fraud that include bursts of activities at different merchants, cards used at merchants never used before, larger than normal purchase amounts, etc. 1,191 variables were created that include amount, frequency, day-since, velocity change, Benford’s law, etc. Benford’s law variables were removed because while they are viable for forensic analysis, they were not properly formed for this project.

After a total of 1,191 variables were created, feature selection was performed through forward selection and a catboost wrapper to select the best 20 variables to deploy in machine learning models. Kolmogorov-Smirnov (KS) and Fraud Detection Rate (FDR) at 3% were used to filter out ineffective variables. Finally, the data is divided into three sections for model analysis: training, testing, and out-of-time (OOT). For Training and testing datasets, the model will use the data before November 1st 2010, and OOT is scored on data after that date.

To determine the best model, multiple models were tested with different hyperparameters. Logistic regression is the base linear model. Nonlinear models like random forest, boosted trees, and neural networks were tested after. Light gradient-boosted machine (LGBM) was the best model due to similar training and testing performance, and good OOT score. With light gradient-boosted machine, 53.79% of fraud can be eliminated by declining 3% of total applications to save around $21,480,000 per year.

In short, the results for this credit card transaction fraud analysis are as follows. Concerning the training dataset, the model can eliminate 82.43% of fraud by declining 3% of the total applications. The model can eliminate 80.31% of fraud by declining 3% of the total applications with the testing dataset. The model can eliminate 53.79% of fraud by declining 3% of the total applications with the OOT dataset.
